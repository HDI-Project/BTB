{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Run on Kubernetes\n",
    "\n",
    "Run benchmarking on a kubernetes cluster with the given configuration.\n",
    "\n",
    "Talks to kubernetes to create `n` amount of new `pods` with a dask worker inside of each\n",
    "forming a `dask` cluster. Then, a function specified from `config` is being imported and\n",
    "run with the given arguments. The tasks created by this `function` are being run on the\n",
    "`dask` cluster for distributed computation.\n",
    "\n",
    "The config dict must contain the following sections:\n",
    "* run\n",
    "* dask_cluster\n",
    "* output\n",
    "\n",
    "Within the `run` section you need to specify:\n",
    "* function:\n",
    "    The complete python path to the function to be run.\n",
    "* args:\n",
    "    A dictionary containing the keyword args that will be used with the given function.\n",
    "\n",
    "Within the `dask_cluster` section you can specify:\n",
    "* workers:\n",
    "    The amount of workers to use.\n",
    "   \n",
    "* worker_config: A dictionary with the following keys:\n",
    "    * resources: A dictionary containig the following keys:\n",
    "        * memory:\n",
    "            The amount of RAM memory.\n",
    "        * cpu:\n",
    "            The amount of cpu's to use.\n",
    "    * image: A docker image to be used (optional).\n",
    "    * setup: A dictionary containing the following keys:\n",
    "        * script: Location to bash script from the docker container to be run.\n",
    "        * git_repository: A dictionary containing the following keys:\n",
    "            * url: Link to the github repository to be cloned.\n",
    "            * reference: A reference to the branch or commit to checkout at.\n",
    "            * install: command run to install this repository.\n",
    "        * pip_packages: A list of pip packages to be installed.\n",
    "        * apt_packages: A list of apt packages to be installed.\n",
    "        \n",
    "Within the `output` section you can specify:\n",
    "* path: The path to a local file or s3 were the file will be saved.\n",
    "* bucket: If given, the path specified previously will be saved as `s3://bucket/path`\n",
    "* key: AWS authentication key to access the bucket.\n",
    "* secret_key: AWS secrect authentication key to access the bucket.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on Kubernetes\n",
    "\n",
    "There are two ways to run the benchmarking process on kubernetes:\n",
    "\n",
    "* `run_dask_function`: start a Dask Cluster using dask-kubernetes and run a function.\n",
    "* `run_on_kubernetes`: run dask function inside a pod using the given config.\n",
    "\n",
    "## Run dask function\n",
    "\n",
    "Talks to kubernetes to create `n` amount of new `pods` with a dask worker inside of each\n",
    "forming a `dask` cluster. Then, a function specified from `config` is being imported and\n",
    "run with the given arguments. The tasks created by this `function` are being run on the\n",
    "`dask` cluster for distributed computation.\n",
    "\n",
    "The config dict must contain the following sections:\n",
    "    * run\n",
    "    * dask_cluster\n",
    "    * output (optional)\n",
    "    \n",
    "*Note* to find more information about the config dict please reffer to Kubernetes in our documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'run': {\n",
    "        'function': 'btb_benchmark.main.run_benchmark',\n",
    "        'args': {\n",
    "            'iterations': 10,\n",
    "            'sample': 4,\n",
    "            'tuners': 'BTB.UniformTuner',\n",
    "            'challenge_types': 'xgboost',\n",
    "            'detailed_output': True,\n",
    "        }\n",
    "    },\n",
    "    'dask_cluster': {\n",
    "        'workers': {\n",
    "            'maximum': 1\n",
    "        },\n",
    "        'worker_config': {\n",
    "            'resources': {\n",
    "                'memory': '2G',\n",
    "                'cpu': 8\n",
    "            },\n",
    "            'image': 'mlbazaar/btb_benchmark:latest',\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at: tcp://192.168.1.132:37203\n",
      "distributed.scheduler - INFO -   dashboard at:                     :8787\n",
      "distributed.scheduler - INFO - Receive client connection: Client-d0d657fa-906a-11ea-97d4-00d8610cc1df\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.0.44:41383', name: tcp://10.244.0.44:41383, memory: 0, processing: 4>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.44:41383\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed - INFO - [##########                              ] | 25% Completed | 0:00:12.417366 | 0:00:37.252081 | 2020-05-07 13:59:12.964920\n",
      "distributed - INFO - [####################                    ] | 50% Completed | 0:00:16.149690 | 0:00:16.149685 | 2020-05-07 13:58:55.594847\n",
      "distributed - INFO - [##############################          ] | 75% Completed | 0:00:19.483861 | 0:00:06.494619 | 2020-05-07 13:58:49.273953\n",
      "distributed - INFO - [########################################] | 100% Completed | 0:01:16.686597 | 0:00:00 | 2020-05-07 13:59:39.982070\n",
      "distributed.scheduler - INFO - Remove client Client-d0d657fa-906a-11ea-97d4-00d8610cc1df\n",
      "distributed.scheduler - INFO - Remove client Client-d0d657fa-906a-11ea-97d4-00d8610cc1df\n",
      "distributed.scheduler - INFO - Close client connection: Client-d0d657fa-906a-11ea-97d4-00d8610cc1df\n",
      "distributed.scheduler - INFO - Scheduler closing...\n",
      "distributed.scheduler - INFO - Scheduler closing all comms\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.0.44:41383', name: tcp://10.244.0.44:41383, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.44:41383\n",
      "distributed.scheduler - INFO - Lost all workers\n"
     ]
    }
   ],
   "source": [
    "from btb_benchmark.kubernetes import run_dask_function\n",
    "\n",
    "results = run_dask_function(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on kubernetes cluster\n",
    "\n",
    "Run dask function inside a pod using the given config.\n",
    "\n",
    "Create a pod, using the local kubernetes configuration that starts a Dask Cluster\n",
    "using dask-kubernetes and runs a function specified within the `config` dictionary.\n",
    "\n",
    "*Note* if you are runing on a different *namespace* that's not `default` you can pass this argument to\n",
    "the `run_on_kubernetes` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pod created.\n"
     ]
    }
   ],
   "source": [
    "from btb_benchmark.kubernetes import run_on_kubernetes\n",
    "\n",
    "run_on_kubernetes(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After runing `run_on_kubernetes` you can check that the pod has been created by runing the following command\n",
    "on your terminal:\n",
    "```bash\n",
    "kubectl get pods\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
