{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import boston dataset\n",
    "First, let's import our datatset, in this case, we will use the regression dataset `Boston`\n",
    "that comes with `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston as load_dataset\n",
    "\n",
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import train_test_split and generate X_train, X_test, y_train, y_test\n",
    "Following, we will split our data in `train, test` using `train_test_split` also from `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, dataset.target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the metric and the estimators\n",
    "For this example, we will use `RandomForestRegressor` against `ExtraTreesRegressor`, we want to\n",
    "tune them and see wich of them will be the better one for this problem. We also will use `r2_score` as\n",
    "a scorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7149946643194653"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# NOTE: The default hyperparameters are intentionally bad\n",
    "# to give more room for improvement during the BTBSession demo\n",
    "default_hyperparams = {\n",
    "    'n_estimators': 2,\n",
    "    'max_features': 'log2',\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, **default_hyperparams)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "r2_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6108880572971567"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = ExtraTreesRegressor(random_state=0, **default_hyperparams)\n",
    "\n",
    "et.fit(X_train, y_train)\n",
    "pred = et.predict(X_test)\n",
    "\n",
    "r2_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create a Tunable dict\n",
    "Following we will create a dictionary which has as keys the names of our `tunables` and as values\n",
    "they weill contain the `tunable hyperparameters`. Those `tunable hyperparameters` are the ones that will\n",
    "be tuned by the `btb.session.BTBSession` in order to improve the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunables = {\n",
    "    'random_forest': {\n",
    "        'n_estimators': {'type': 'int', 'default': 2, 'range': [1, 1000]},\n",
    "        'max_features': {'type': 'str', 'default': 'log2', 'range': [None, 'auto', 'log2', 'sqrt']},\n",
    "        'min_samples_split': {'type': 'int', 'default': 2, 'range': [2, 20]},\n",
    "        'min_samples_leaf': {'type': 'int', 'default': 2, 'range': [1, 20]},\n",
    "    },\n",
    "    'extra_trees': {\n",
    "        'n_estimators': {'type': 'int', 'default': 2, 'range': [1, 1000]},\n",
    "        'max_features': {'type': 'str', 'default': 'log2', 'range': [None, 'auto', 'log2', 'sqrt']},\n",
    "        'min_samples_split': {'type': 'int', 'default': 2, 'range': [2, 20]},\n",
    "        'min_samples_leaf': {'type': 'int', 'default': 2, 'range': [1, 20]},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a `score` function\n",
    "As `BTBSession` requieres, we will create a function that scores our estimators. In this case\n",
    "we will use `cross_val_score` and the `r2_scorer` that we imported before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "models = {\n",
    "    'random_forest': RandomForestRegressor,\n",
    "    'extra_trees': ExtraTreesRegressor,\n",
    "}\n",
    "\n",
    "def build_model(name, hyperparameters):\n",
    "    model_class = models[name]\n",
    "    return model_class(random_state=0, **hyperparameters)\n",
    "\n",
    "def score_model(name, hyperparameters):\n",
    "    model = build_model(name, hyperparameters)\n",
    "    r2_scorer = make_scorer(r2_score)\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring=r2_scorer)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate BTBSession\n",
    "After creating our `tunables` and our `scoring` function, we can proceed to `tune` them. (We will use\n",
    "`verbose=True` in order to print a bar with the progress during `run`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.session import BTBSession\n",
    "\n",
    "session = BTBSession(tunables, score_model, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run method\n",
    "The main method, that returns the `best_proposal` for `n` iterations, is `run`. This method\n",
    "will iterate thro the list, create proposals and score them against the `scoring` function.\n",
    "Bear in mind that `BTBSession` will first try the default configuration atleast once, which means\n",
    "that each `tunable` is given atleast one run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1649ae62e97d4675869e8d8281dc67ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'd02e055a1279d42b74169151047c542c',\n",
       " 'name': 'extra_trees',\n",
       " 'config': {'n_estimators': 2,\n",
       "  'max_features': 'log2',\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 2},\n",
       " 'score': 0.7294475145162741}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(iterations=2)  # Run two iterations, this will execute with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'40e9094fa4b1901410b62c95ecbe9a21': {'id': '40e9094fa4b1901410b62c95ecbe9a21',\n",
       "  'name': 'random_forest',\n",
       "  'config': {'n_estimators': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2},\n",
       "  'score': 0.7096417128432014},\n",
       " 'd02e055a1279d42b74169151047c542c': {'id': 'd02e055a1279d42b74169151047c542c',\n",
       "  'name': 'extra_trees',\n",
       "  'config': {'n_estimators': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2},\n",
       "  'score': 0.7294475145162741}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate over more iterations\n",
    "When calling `run` again, we will continue from the last checkpoint, which in this case was at `iteration=2`.\n",
    "Let's give it some more `iterations` and save the `best_proposal` in a variable, (you can always access it from\n",
    "`session.best_proposal`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8b3795bd504590994b7096c2107dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_proposal = session.run(iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best_proposal\n",
    "A dictionary which has as `name` the key value to the model given name and `config` the best\n",
    "configuration found for it and `score`, the score obtained with the `scoring` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'fb22d93a7753e26834d07ca9c9a8dd40',\n",
       " 'name': 'extra_trees',\n",
       " 'config': {'n_estimators': 611,\n",
       "  'max_features': 'log2',\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1},\n",
       " 'score': 0.8686338104323431}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model with the tuned configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = build_model(best_proposal['name'], best_proposal['config'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model and score it.\n",
    "Bear in mind that the `r2_scorer` may give you lower score regarding the `cross_val_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8007483075651847"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "pred = best_model.predict(X_test)\n",
    "\n",
    "r2_score(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
