{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTBSession\n",
    "\n",
    "A ``BTBSession`` represents the process of selecting and tuning several tunables\n",
    "until the best possible configuration for a specific ``scorer`` is found.\n",
    "\n",
    "For this, a loop is run in which for each iteration a combination of a ``Selector`` and\n",
    "``Tuner`` is used to decide which tunable to score next and with which hyperparameters.\n",
    "\n",
    "While running, the ``BTBSession`` handles the errors discarding, if configured to do so,\n",
    "the tunables that have reached as many errors as the user specified.\n",
    "\n",
    "Below there is a short example using ``BTBSession`` to perform tuning over\n",
    "``ExtraTreesRegressor`` and ``RandomForestRegressor`` ensemblers from `scikit-learn`_\n",
    "and both of them are evaluated against the `Boston dataset`_ regression problem.\n",
    "\n",
    "Let's import all the needed packages in order to run our code. We will import the ``load_boston``\n",
    "from ``sklearn.datasets`` and two estimators (``ExtraTreesRegressor`` and ``RandomForest``). In\n",
    "order to evaluate them we will use the ``r2_score``. We will also be importing some basics in order\n",
    "to perform cross validation and split our data from the ``model_selection``. And finally we will\n",
    "import our ``BTBSession``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.datasets import load_boston as load_dataset\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from btb.session import BTBSession\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create a dictionary to reffer to each model of our choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'random_forest': RandomForestRegressor,\n",
    "    'extra_trees': ExtraTreesRegressor,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will proceed to create a function that will *build the model* and another one that will\n",
    "*score* the model. This is needed because ``BTBSession.score`` is being called with the\n",
    "``tunable_name`` and ``config``. So pretty much the scoring function must be prepared to recive\n",
    "this two parameters and generate a ``score``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(name, hyperparameters):\n",
    "    model_class = models[name]\n",
    "    return model_class(random_state=0, **hyperparameters)\n",
    "\n",
    "def score_model(name, hyperparameters):\n",
    "    model = build_model(name, hyperparameters)\n",
    "    r2_scorer = make_scorer(r2_score)\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring=r2_scorer, cv=5)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have this two functions, we can proceed on loading the dataset, generating its splits\n",
    "and create a list of ``tunables`` for our ``BTBSession``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, dataset.target, test_size=0.3, random_state=0)\n",
    "\n",
    "tunables = {\n",
    "    'random_forest': {\n",
    "        'max_features': {\n",
    "            'type': 'str',\n",
    "            'default': 'log2',\n",
    "            'range': [None, 'auto', 'log2', 'sqrt']\n",
    "        },\n",
    "        'min_samples_split': {\n",
    "            'type': 'int',\n",
    "            'default': 2,\n",
    "            'range': [2, 20]\n",
    "        },\n",
    "        'min_samples_leaf': {\n",
    "            'type': 'int',\n",
    "            'default': 2,\n",
    "            'range': [1, 20]\n",
    "        },\n",
    "    },\n",
    "    'extra_trees': {\n",
    "        'max_features': {\n",
    "            'type': 'str',\n",
    "            'default': 'log2',\n",
    "            'range': [None, 'auto', 'log2', 'sqrt']\n",
    "        },\n",
    "        'min_samples_split': {\n",
    "            'type': 'int',\n",
    "            'default': 2,\n",
    "            'range': [2, 20]\n",
    "        },\n",
    "        'min_samples_leaf': {\n",
    "            'type': 'int',\n",
    "            'default': 2,\n",
    "            'range': [1, 20]\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have everything set up, we can proceed to generate our ``BTBSession`` and run it in\n",
    "order to evaluate wich of this two machine learning models will obtain a better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '9198dd0b94d325315fa023d2f8b417a6',\n",
       " 'name': 'random_forest',\n",
       " 'config': {'max_features': 'log2',\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 2},\n",
       " 'score': 0.8325913357770718}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = BTBSession(tunables, score_model)\n",
    "session.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this 5 iterations are done, our session will return the ``best_proposal``, or we can access\n",
    "it thro ``session.best_proposal``. Inside this dictionary we will find the ``name``, ``config`` and\n",
    "the ``score`` for the best configuration found during those 5 iterations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
