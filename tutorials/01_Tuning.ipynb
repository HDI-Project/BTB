{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning\n",
    "\n",
    "## Defining a Tuning Problem\n",
    "\n",
    "A tuning problem in machine learning comes as choosing a set of\n",
    "optimal `hyperparameters` for a `learning algorithm`.\n",
    "\n",
    "By providing a set of `hyperparameters` and their range of values,\n",
    "we have a `tuning problem` that can be solved by finding the optimal\n",
    "values for those hyperparameters and obtain the best performance possible.\n",
    "\n",
    "\n",
    "## What is a Hyperparameter?\n",
    "\n",
    "In **BTB** a hyperparameter is a class that represents an object\n",
    "which given a configuration, contains the methods that **BTB** needs\n",
    "in order to find the optimal value for this parameter.\n",
    "\n",
    "### Types of Hyperparameters\n",
    "\n",
    "- `BooleanHyperParam`: boolean parameters i.e: `True` or `False`.\n",
    "- `CategoricalHyperParam`: categorical parameters i.e: \"foo\", \"bar\".\n",
    "- `FloatHyperParam`: `float` parameters i.e: `0.0 - 1.0`\n",
    "- `IntHyperParam`: `int` parameters i.e: `0 - 1`\n",
    "\n",
    "#### Creating a hyperparameter\n",
    "\n",
    "In order to create a hyperparameter, we have to first import the\n",
    "hyperparameter that we are about to use.\n",
    "\n",
    "##### BooleanHyperParam\n",
    "\n",
    "This hyperparameter is used for parameters that represent boolean values. This hyperparameter has the following\n",
    "arguments:\n",
    "\n",
    "- `default`: default value for the hyperparameter. Defaults to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning.hyperparams import BooleanHyperParam\n",
    "\n",
    "bool_hp = BooleanHyperParam(default=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CategoricalHyperParam\n",
    "\n",
    "This hyperparameter is used for hyperparameters that use categorical values. The following arguments\n",
    "are accepted by this hyperparameter:\n",
    "- `choices`: list of values that the hyperparameter can be.\n",
    "- `default`: default value for the hyperparameter to take. Defaults to the first item in ``choices``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning.hyperparams import CategoricalHyperParam\n",
    "\n",
    "values = ['a', 'b', 'c']\n",
    "categorical_hp = CategoricalHyperParam(choices=values, default='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FloatHyperParam\n",
    "\n",
    "This hyperparameter is used for parameters that use `float` values.\n",
    "It allows you to instantiate an open or a closed range of values\n",
    "by providing the following arguments:\n",
    "\n",
    "- `min` (float): minimum value that this hyperparameter can take, by default is ``None`` which will take the system's minimum float value possible.\n",
    "- `max` (float): maximum value that this hyperparameter can take, by default is ``None`` which will take the system's maximum float value possible.\n",
    "- `default` (float): number that represents the default value for the hyperparameter. Defaults to ``self.min``.\n",
    "- `include_min` (bool): Either or not to include the minimum value, by default is ``True``.\n",
    "- `include_max` (bool): Either or not to include the maximum value, by default is ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning.hyperparams import FloatHyperParam\n",
    "\n",
    "float_hp = FloatHyperParam(min=0, max=1, default=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IntHyperParam\n",
    "\n",
    "This hyperparameter is used for parameters that use `int` values.\n",
    "It allows you to instantiate an open or a closed range of values\n",
    "by providing the following arguments:\n",
    "\n",
    "- `min` (int): minimum value that this hyperparameter can take, by default is ``None`` which will take the system's minimum int value possible.\n",
    "- `max` (int): maximum value that this hyperparameter can take, by default is ``None`` which will take the system's maximum int value possible.\n",
    "- `default` (int): number that represents the default value for the hyperparameter. Defaults to ``self.min``.\n",
    "- `step` (int): Increase amount to take for each sample. Defaults to 1.\n",
    "- `include_min` (bool): Either or not to include the minimum value, by default is ``True``.\n",
    "- `include_max` (bool): Either or not to include the maximum value, by default is ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning.hyperparams import IntHyperParam\n",
    "\n",
    "int_hp = IntHyperParam(min=1, max=10, default=5, include_min=False, include_max=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Tunable?\n",
    "\n",
    "`Tunable` is a class specifically designed to represent a tuning\n",
    "problem. This class is a collection of `Hyperparameter` objects\n",
    "and provides an api that **BTB** uses to solve a tuning problem.\n",
    "\n",
    "### Creating a Tunable\n",
    "\n",
    "#### Dictionary of hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning.tunable import Tunable\n",
    "from btb.tuning.hyperparams import (\n",
    "    BooleanHyperParam, CategoricalHyperParam, IntHyperParam, FloatHyperParam)\n",
    "\n",
    "hyperparams = {\n",
    "    'bhp': BooleanHyperParam(default=False),\n",
    "    'chp': CategoricalHyperParam(choices=['foo', 'bar'], default='foo'),\n",
    "    'fhp': FloatHyperParam(min=0, max=1, default=0.5),\n",
    "    'ihp': IntHyperParam(min=1, max=10, default=2),\n",
    "}\n",
    "\n",
    "tunable = Tunable(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a dictionary representing the hyperparameters\n",
    "\n",
    "The class `Tunable` provides a method `from_dict` that accepts as an input a python dictionary\n",
    "containing as `key` the given name for the hyperparameter and as value a dictionary containing\n",
    "the following keys:\n",
    "\n",
    "- `type` (str): ``bool`` for ``BoolHyperParam``, ``int`` for ``IntHyperParam``, ``float`` for ``FloatHyperParam``, ``str`` for ``CategoricalHyperParam``.\n",
    "- `range` or `values` (list): range / values that this hyperparameter can take, in case of ``CategoricalHyperParam`` those will be used as the ``choices``, for ``NumericalHyperParams`` the ``min`` value will be used as the minimum value and the ``max`` value will be used as the ``maximum`` value.\n",
    "- `default` (str, bool, int, float or None): The default value for the hyperparameter. \n",
    "\n",
    "The previously created `Tunable` can be created using the following dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'bhp': {\n",
    "        'type': 'bool',\n",
    "        'default': False\n",
    "    },\n",
    "    'chp': {\n",
    "        'type': 'str',\n",
    "        'values': ['foo', 'bar'],\n",
    "        'default': 'foo'\n",
    "    },\n",
    "    'fhp': {\n",
    "        'type': 'float',\n",
    "        'values': [0, 1],\n",
    "        'default': 0.5\n",
    "    },\n",
    "    'ihp': {\n",
    "        'type': 'int',\n",
    "        'values': [1, 10],\n",
    "        'default': 2\n",
    "    }\n",
    "}\n",
    "\n",
    "tunable = Tunable.from_dict(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  What is a Tuner?\n",
    "\n",
    "Tuners are specifically designed to speed up the process of selecting the\n",
    "optimal hyperparameter values for a specific machine learning problem.\n",
    "\n",
    "``btb.tuning.tuners`` defines Tuners: classes with a fit/predict/propose interface for\n",
    "suggesting sets of hyperparameters.\n",
    "\n",
    "This is done by following a Bayesian Optimization approach and iteratively:\n",
    "\n",
    "* letting the tuner propose new sets of hyper parameter\n",
    "* fitting and scoring the model with the proposed hyper parameters\n",
    "* passing the score obtained back to the tuner\n",
    "\n",
    "At each iteration the tuner will use the information already obtained to propose\n",
    "the set of hyper parameters that it considers that have the highest probability\n",
    "to obtain the best results.\n",
    "\n",
    "### Creating a Tuner\n",
    "\n",
    "In order to create a `BTB` tuner, we will need a `Tunable` object that represents the\n",
    "tuning problem. **Bear in mind** that you can import `Tunable` and the hyperparameters\n",
    "from `btb.tuning`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning import FloatHyperParam, IntHyperParam, Tunable\n",
    "\n",
    "tuning_problem = Tunable({\n",
    "    'fhp': FloatHyperParam(min=0, max=1),\n",
    "    'ihp': IntHyperParam(min=1, max=10)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `tuning_problem` let's import a `GPTuner` from `btb.tuning.tuners` and create\n",
    "a `Tuner` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning.tuners import GPTuner\n",
    "\n",
    "tuner = GPTuner(tuning_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuner usage\n",
    "\n",
    "The tuner is ment to be used with two methods:\n",
    "\n",
    "##### Propose\n",
    "\n",
    "This method will propose one or more new hyperparameter configuration(s)\n",
    "by using the following aproach:\n",
    "1. Create candidates.\n",
    "2. Use acquisition function to acquire candidates.\n",
    "3. Return the selected candidate to be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fhp': 0.8970714137989368, 'ihp': 7}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal = tuner.propose()\n",
    "proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Record\n",
    "\n",
    "This method will record the result of one trial. Then  it will\n",
    "`re-fit` the meta-model in order to generate better proposals:\n",
    "1. Append trial to internal results store.\n",
    "2. Re-fit meta-model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0.5\n",
    "tuner.record(proposal, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, those methods are ment to be used in a loop, that:\n",
    "\n",
    "1. Propose.\n",
    "2. Scores the proposal.\n",
    "3. Records the proposal.\n",
    "\n",
    "##### Tuning loop example\n",
    "\n",
    "In order to create a `tuning loop` we will need a `scoring function` and\n",
    "the `Tunable` for this `scoring function`. In this example, we will use the\n",
    "mathematical function [Rosenbrock](https://en.wikipedia.org/wiki/Rosenbrock_function),\n",
    "wich takes as input arguments: `x` and `y`.\n",
    "\n",
    "Let's define this function in `python`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x, y):\n",
    "    return -1 * ((1 - x)**2 + 100 * (y - x**2)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create our `tunable` which will take values from `-50` to `50` for both `x` and `y`,\n",
    "then, create a `Tuner` with that `tunable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning import GPTuner, IntHyperParam, Tunable\n",
    "\n",
    "tunable = Tunable({\n",
    "    'x': IntHyperParam(min=-50, max=50),\n",
    "    'y': IntHyperParam(min=-50, max=50)\n",
    "})\n",
    "\n",
    "tuner = GPTuner(tunable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our tuning loop that will propose and record the obtained scores for 100 iterations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    proposal = tuner.propose()\n",
    "    score = rosenbrock(**proposal)\n",
    "    tuner.record(proposal, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemented tuners\n",
    "\n",
    "**BTB** has the following three tuners available:\n",
    "- [UniformTuner](https://github.com/HDI-Project/BTB/blob/master/btb/tuning/tuners/uniform.py): Uses a Tuner that samples proposals randomly using a uniform distribution.\n",
    "- [GPTuner](https://github.com/HDI-Project/BTB/blob/master/btb/tuning/tuners/gaussian_process.py): Uses a Bayesian Tuner that optimizes proposals using a GaussianProcess metamodel.\n",
    "- [GPEiTuner](https://github.com/HDI-Project/BTB/blob/master/btb/tuning/tuners/gaussian_process.py): Uses a Bayesian Tuner that optimizes proposals using a GaussianProcess metamodel and an Expected Improvement acquisition function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuners Leaderboard\n",
    "\n",
    "Currently we have a [Benchmarking](https://github.com/HDI-Project/BTB/tree/master/benchmark)\n",
    "process that evaluates the `tuners` performance against each other\n",
    "this are the latest results that we obtained for the `BTB` tuners.\n",
    "\n",
    "\n",
    "| tuner                   | with ties | without ties |\n",
    "|-------------------------|-----------|--------------|\n",
    "| `BTB.GPEiTuner`         |    **35** |            7 |\n",
    "| `BTB.GPTuner`           |    33     |        **8** |\n",
    "| `BTB.UniformTuner`      |    29     |            2 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
