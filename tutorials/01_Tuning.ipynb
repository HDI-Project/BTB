{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning\n",
    "\n",
    "## Defining a Tuning Problem\n",
    "\n",
    "A tuning problem consists of the process of finding an optimal configuration of arguments or hyperparameters for a function that can be evaluated to produce a score.\n",
    "\n",
    "\n",
    "## What is a Hyperparameter?\n",
    "\n",
    "A hyperparameter is each one of the arguments that can be optimized on our tuning problem.\n",
    "Hyperparameters can be of different types and can be defined with a set of constraints\n",
    "regarding possible values that they can take.\n",
    "\n",
    "In BTB, hyperparameters are represented using a family of classes called HyperParams.\n",
    "This is the list of the HyperParams that are currently implemented in BTB:\n",
    "\n",
    "- `BooleanHyperParam`: boolean parameters i.e: `True` or `False`.\n",
    "- `CategoricalHyperParam`: categorical parameters i.e: \"foo\", \"bar\".\n",
    "- `FloatHyperParam`: `float` parameters i.e: `0.0 - 1.0`\n",
    "- `IntHyperParam`: `int` parameters i.e: `0 - 1`\n",
    "\n",
    "## Creating a HyperParam\n",
    "\n",
    "### BooleanHyperParam\n",
    "\n",
    "The `BooleanHyperParam` is used for parameters that represent boolean values.\n",
    "This HyperParam has the following arguments:\n",
    "\n",
    "- `default`: default value for the hyperparameter. Defaults to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignoring warnings from external libraries that are irrelevant\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning.hyperparams import BooleanHyperParam\n",
    "\n",
    "bool_hp = BooleanHyperParam(default=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CategoricalHyperParam\n",
    "\n",
    "The `CategoricalHyperParam` is used for parameters that use categorical values. This HyperParam accepts the following arguments:\n",
    "- `choices`: list of values that the hyperparameter can be.\n",
    "- `default`: default value for the hyperparameter to take. Defaults to the first item in ``choices``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning.hyperparams import CategoricalHyperParam\n",
    "\n",
    "values = ['a', 'b', 'c']\n",
    "categorical_hp = CategoricalHyperParam(choices=values, default='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FloatHyperParam\n",
    "\n",
    "The `FloatHyperparam` is used for parameters that use `float` values.\n",
    "This HyperParam accepts the following arguments:\n",
    "\n",
    "- `min` (float): minimum value that this hyperparameter can take, by default is ``None`` which will take the system's minimum float value possible.\n",
    "- `max` (float): maximum value that this hyperparameter can take, by default is ``None`` which will take the system's maximum float value possible.\n",
    "- `default` (float): number that represents the default value for the hyperparameter. Defaults to ``self.min``.\n",
    "- `include_min` (bool): Either or not to include the minimum value, by default is ``True``.\n",
    "- `include_max` (bool): Either or not to include the maximum value, by default is ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning.hyperparams import FloatHyperParam\n",
    "\n",
    "float_hp = FloatHyperParam(min=0, max=1, default=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IntHyperParam\n",
    "\n",
    "The `IntHyperParam` is used for parameters that use `int` values.\n",
    "This HyperParam accepts the following arguments:\n",
    "\n",
    "- `min` (int): minimum value that this hyperparameter can take, by default is ``None`` which will take the system's minimum int value possible.\n",
    "- `max` (int): maximum value that this hyperparameter can take, by default is ``None`` which will take the system's maximum int value possible.\n",
    "- `default` (int): number that represents the default value for the hyperparameter. Defaults to ``self.min``.\n",
    "- `step` (int): Increase amount to take for each sample. Defaults to 1.\n",
    "- `include_min` (bool): Either or not to include the minimum value, by default is ``True``.\n",
    "- `include_max` (bool): Either or not to include the maximum value, by default is ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning.hyperparams import IntHyperParam\n",
    "\n",
    "int_hp = IntHyperParam(min=1, max=10, default=5, include_min=False, include_max=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Tunable?\n",
    "\n",
    "In BTB, a tuning problem is represented using the class Tunable, which consists of a collection of HyperParams which will be all tuned at once to find the optiomal solution to our Tuning Problem.\n",
    "\n",
    "### Creating a Tunable\n",
    "\n",
    "Tunable instances can be created in two ways:\n",
    "\n",
    "#### Using HyperParam instances\n",
    "\n",
    "One way of using the Tunable is to create HyperParam instances for\n",
    "each one of the hyperparameters that we want to tune and pass them as a dict to the Tunable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning.tunable import Tunable\n",
    "from btb.tuning.hyperparams import (\n",
    "    BooleanHyperParam, CategoricalHyperParam, IntHyperParam, FloatHyperParam)\n",
    "\n",
    "hyperparams = {\n",
    "    'bhp': BooleanHyperParam(default=False),\n",
    "    'chp': CategoricalHyperParam(choices=['foo', 'bar'], default='foo'),\n",
    "    'fhp': FloatHyperParam(min=0, max=1, default=0.5),\n",
    "    'ihp': IntHyperParam(min=1, max=10, default=2),\n",
    "}\n",
    "\n",
    "tunable = Tunable(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a dict representation\n",
    "\n",
    "Alternatively, the Tunable can be represented as a dictionary with all the details of each hyperparameter specified, which can then be stored as a JSON file or in other non-python format.\n",
    "\n",
    "A python dictionary format would contain as key the given name for the parameter and as value a dictionary containing the following keys\n",
    "\n",
    "- `type` (str): ``bool`` for ``BoolHyperParam``, ``int`` for ``IntHyperParam``, ``float`` for ``FloatHyperParam``, ``str`` for ``CategoricalHyperParam``.\n",
    "- `range` or `values` (list): range / values that this hyperparameter can take, in case of ``CategoricalHyperParam`` those will be used as the ``choices``, for ``NumericalHyperParams`` the ``min`` value will be used as the minimum value and the ``max`` value will be used as the ``maximum`` value.\n",
    "- `default` (str, bool, int, float or None): The default value for the hyperparameter. \n",
    "\n",
    "Once this dict is written, it can be passed to the `from_dict` method.\n",
    "\n",
    "The previously created Tunable can be created using the following dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'bhp': {\n",
    "        'type': 'bool',\n",
    "        'default': False\n",
    "    },\n",
    "    'chp': {\n",
    "        'type': 'str',\n",
    "        'values': ['foo', 'bar'],\n",
    "        'default': 'foo'\n",
    "    },\n",
    "    'fhp': {\n",
    "        'type': 'float',\n",
    "        'values': [0, 1],\n",
    "        'default': 0.5\n",
    "    },\n",
    "    'ihp': {\n",
    "        'type': 'int',\n",
    "        'values': [1, 10],\n",
    "        'default': 2\n",
    "    }\n",
    "}\n",
    "\n",
    "tunable = Tunable.from_dict(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  What is a Tuner?\n",
    "\n",
    "Tuners are classes with a fit/predict/propose interface for\n",
    "suggesting sets of hyperparameters. This are specifically designed\n",
    "to speed up the process of selecting the optimal hyperparameter values\n",
    "for a specific tuning problem.\n",
    "\n",
    "## Using a Tuner\n",
    "\n",
    "The **BTB** Tuners are used by following a Bayesian Optimization approach and iteratively:\n",
    "\n",
    "* letting the tuner propose new sets of hyper parameter\n",
    "* fitting and scoring the model with the proposed hyper parameters\n",
    "* passing the score obtained back to the tuner\n",
    "\n",
    "At each iteration the tuner will use the information already obtained to propose\n",
    "the set of hyper parameters that it considers that have the highest probability\n",
    "to obtain the best results.\n",
    "\n",
    "### Creating a Tuner\n",
    "\n",
    "We will be using a `GPTuner` that accepts the following arguments:\n",
    "\n",
    "- `tunable` (btb.tuning.tunable.Tunable): Instance of a tunable class containing hyperparameters to be tuned.\n",
    "- `num_candidates` (int): Number of samples to generate and select the best of it for each proposal. Defaults to 1000.\n",
    "- `maximize` (bool): If ``True`` the model will understand that the score bigger is better, if ``False`` the smaller is better. Defaults to ``True``.\n",
    "- `min_trials` (int): Number of recorded ``trials`` needed to perform a fitting over the model. Defaults to 2.\n",
    "\n",
    "*Bear in mind* that the `tunable` is a requiered argument in order to create a `Tuner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning import hyperparams as hp\n",
    "from btb.tuning.tuners import GPTuner\n",
    "\n",
    "tunable = Tunable({\n",
    "    'fhp': hp.FloatHyperParam(min=0, max=1),\n",
    "    'ihp': hp.IntHyperParam(min=1, max=10)\n",
    "})\n",
    "\n",
    "tuner = GPTuner(tunable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propose\n",
    "\n",
    "This method will propose one or more new hyperparameter configuration(s)\n",
    "by using the following aproach:\n",
    "\n",
    "1. Create `num_candidates` amount of candidates.\n",
    "2. Use acquisition function to select the best candidates.\n",
    "3. Return the best selected candidate(s) to be evaluated.\n",
    "\n",
    "This method accepts the following arguments:\n",
    "- `n` (int): Number of candidates to create. Defaults to 1.\n",
    "- `allow_duplicates` (bool): If it's False, the tuner will propose trials that are not recorded, otherwise will generate trials that can be repeated. Defaults to ``False``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fhp': 0.1546118292012293, 'ihp': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal = tuner.propose()\n",
    "proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record\n",
    "\n",
    "This method will record the result of one trial or more trials. Then  it will\n",
    "`re-fit` the meta-model (if `min_trials` is reached) in order to generate *posterior* proposals:\n",
    "\n",
    "1. Append trial to internal results store.\n",
    "2. Re-fit meta-model if the `min_trials` is reached.\n",
    "\n",
    "*Bear in mind* that the proposals that we want to record must have the same parameter names as the tunable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0.5\n",
    "tuner.record(proposal, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning loop example\n",
    "\n",
    "The tuners are ment to be used in a loop that perform the following three steps over and over:\n",
    "\n",
    "1. Propose.\n",
    "2. Score the proposal.\n",
    "3. Record the proposal.\n",
    "\n",
    "In this example we will use the [wine dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine)\n",
    "and tune the [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) that will atempt to solve it.\n",
    "\n",
    "Next, we will load the dataset and split it in two partitions, train and test, which we will use later on to evaluate the performance of our machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, dataset.target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataset ready, we will import our model and create the hyperparams for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from btb.tuning import hyperparams as hp\n",
    "\n",
    "# define the SGDClassifier Tunable\n",
    "hyperparams = {\n",
    "    \"alpha\": FloatHyperParam(min=0.0001, max=1, default=0.0001),\n",
    "    \"max_iter\": IntHyperParam(min=1, max=5000, default=1000),\n",
    "    \"tol\": FloatHyperParam(min=1e-3, max=1, default=1e-3),\n",
    "    \"shuffle\": BooleanHyperParam(default=True) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import our tuner and instantiate it with a tunable using the previous hyperparams, wich will tune the SGDClassifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning import Tunable\n",
    "from btb.tuning.tuners import GPTuner\n",
    "\n",
    "tunable = Tunable(hyperparams)\n",
    "tuner = GPTuner(tunable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we start the tuning loop in which we iteratively:\n",
    "\n",
    "1. let the tuner propose new sets of hyper parameter\n",
    "2. fit and scoring the model with the proposed hyper parameters\n",
    "3. pass the score obtained back to the tuner \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score obtained:  0.7962962962962963\n",
      "Best parameters:  {'alpha': 0.784797005036952, 'max_iter': 2135, 'tol': 0.002603875854038042, 'shuffle': True}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    proposal = tuner.propose()\n",
    "    model = SGDClassifier(**proposal)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_params = proposal\n",
    "        best_score = score\n",
    "        \n",
    "    tuner.record(proposal, score)\n",
    "    \n",
    "print('Best score obtained: ', best_score)\n",
    "print('Best parameters: ', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit our model with the best parameters obtained: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.784797005036952, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=2135, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True,\n",
       "              tol=0.002603875854038042, validation_fraction=0.1, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDClassifier(**best_params)\n",
    "model.fit(dataset.data, dataset.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implemented tuners\n",
    "\n",
    "**BTB** has the following three tuners available:\n",
    "- [UniformTuner](https://github.com/HDI-Project/BTB/blob/master/btb/tuning/tuners/uniform.py): Uses a Tuner that samples proposals randomly using a uniform distribution.\n",
    "- [GPTuner](https://github.com/HDI-Project/BTB/blob/master/btb/tuning/tuners/gaussian_process.py): Uses a Bayesian Tuner that optimizes proposals using a GaussianProcess metamodel.\n",
    "- [GPEiTuner](https://github.com/HDI-Project/BTB/blob/master/btb/tuning/tuners/gaussian_process.py): Uses a Bayesian Tuner that optimizes proposals using a GaussianProcess metamodel and an Expected Improvement acquisition function.\n",
    "\n",
    "### Leaderboard\n",
    "\n",
    "Currently we have a [Benchmarking](https://github.com/HDI-Project/BTB/tree/master/benchmark)\n",
    "process that evaluates the `tuners` performance against each other\n",
    "this are the latest results that we obtained for the `BTB` tuners.\n",
    "\n",
    "\n",
    "| tuner                   | with ties | without ties |\n",
    "|-------------------------|-----------|--------------|\n",
    "| `Ax.optimize`           |    237    |       **39** |\n",
    "| `BTB.GPEiTuner`         |    233    |           19 |\n",
    "| `BTB.GPTuner`           |    235    |           25 |\n",
    "| `BTB.UniformTuner`      |    197    |            2 |\n",
    "| `HyperOpt.tpe`          |    206    |           11 |\n",
    "| `SMAC.HB4AC`            |    192    |            1 |\n",
    "| `SMAC.SMAC4HPO_EI`      |  **241**  |           36 |\n",
    "| `SMAC.SMAC4HPO_LCB`     |    222    |           17 |\n",
    "| `SMAC.SMAC4HPO_PI`      |  **241**  |           37 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
