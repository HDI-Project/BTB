{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selectors\n",
    "\n",
    "## Introduction\n",
    "\n",
    "A selector chooses from a set of discrete options by evaluating\n",
    "each of their past performances. Those use a multi-armed bandit\n",
    "technique to determine which option to select next.\n",
    "\n",
    "The selectors are intended to be used in combination with `tuners` in order to find\n",
    "out and decide which model seems to get the best results once it is properly fine tuned.\n",
    "\n",
    "## Usage examlpe\n",
    "\n",
    "In order to use the selector we will create a ``Tuner`` instance for each model that we want to try out, as well as the ``Selector`` instance.\n",
    "\n",
    "In this example we will use the [iris dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n",
    "and tune two estimators:\n",
    "- [RandomForestClassifier]()\n",
    "- [SGDC]()\n",
    "\n",
    "\n",
    "We will start by importing our dataset, the estimators, the\n",
    "train-test-splitter (we will also import a `trange` object just to\n",
    "preaty print the progress bar and we will suppress the warnings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import trange\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the dataset, split it in to train and test and\n",
    "create a dictionary with the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, dataset.target, test_size=0.3, random_state=0)\n",
    "\n",
    "models = {\n",
    "    'RF': RandomForestClassifier,\n",
    "    'SGDC': SGDClassifier\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following we will import a `UCB1` selector from **BTB** and also\n",
    "we will import some hyperparameters,\n",
    "[Tunable](https://github.com/HDI-Project/BTB/tree/master/tutorials/01_Tuners.ipynb)\n",
    "and [Tuner](https://github.com/HDI-Project/BTB/tree/master/tutorials/02_Tuners.ipynb). Then\n",
    "we will create one `Tunable` object for each `model` and one `Tuner`\n",
    "for each `Tunable`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.selection import UCB1\n",
    "from btb.tuning.hyperparams import FloatHyperParam, IntHyperParam\n",
    "from btb.tuning.tunable import Tunable\n",
    "from btb.tuning.tuners import GPTuner\n",
    "\n",
    "rf_hyperparams = {\n",
    "    'n_estimators': IntHyperParam(min=10, max=500),\n",
    "    'max_depth': IntHyperParam(min=3, max=200)\n",
    "}\n",
    "rf_tunable = Tunable(rf_hyperparams)\n",
    "\n",
    "sgdc_hyperparams = {\n",
    "    'max_iter': IntHyperParam(min=1, max=5000, default=1000),\n",
    "    'tol': FloatHyperParam(min=1e-3, max=1, default=1e-3),\n",
    "}\n",
    "\n",
    "sgdc_tunable = Tunable(sgdc_hyperparams)\n",
    "tuners = {\n",
    "    'RF': GPTuner(rf_tunable),\n",
    "    'SGDC': GPTuner(sgdc_tunable)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we create a `selector` instance with the keys that we\n",
    "used for our models (estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = UCB1(['RF', 'SGDC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we perform the following steps in a loop.\n",
    "\n",
    "1. Pass all the obtained scores to the selector and let it decide which model to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RF'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_choice = selector.select({\n",
    "    'RF': tuners['RF'].scores,\n",
    "    'SGDC': tuners['SGDC'].scores\n",
    "})\n",
    "next_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Obtain a new set of parameters from the indicated tuner and create a model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = tuners[next_choice].propose()\n",
    "model = models[next_choice](**parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluate the score of the new model instance and pass it back to the tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuners[next_choice].record(parameters, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will create a loop to go over for 100 iterations\n",
    "and save the best score, model and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748877ef3a544bfeae3ed822c764e4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for i in trange(100):\n",
    "    next_choice = selector.select({\n",
    "        'RF': tuners['RF'].scores,\n",
    "        'SGDC': tuners['SGDC'].scores\n",
    "    })\n",
    "    parameters = tuners[next_choice].propose()\n",
    "    model = models[next_choice](**parameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    tuners[next_choice].record(parameters, score)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = next_choice\n",
    "        best_params = parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 0.9777777777777777 {'n_estimators': 158, 'max_depth': 85}\n"
     ]
    }
   ],
   "source": [
    "print(best_model, best_score, best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
