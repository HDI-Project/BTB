{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuners \n",
    "\n",
    "## Introduction\n",
    "\n",
    "Tuners are specifically designed to speed up the process of selecting the\n",
    "optimal hyperparameter values for a specific machine learning problem.\n",
    "\n",
    "``btb.tuning.tuners`` defines Tuners: classes with a fit/predict/propose interface for\n",
    "suggesting sets of hyperparameters.\n",
    "\n",
    "This is done by following a Bayesian Optimization approach and iteratively:\n",
    "\n",
    "* letting the tuner propose new sets of hyper parameter\n",
    "* fitting and scoring the model with the proposed hyper parameters\n",
    "* passing the score obtained back to the tuner\n",
    "\n",
    "At each iteration the tuner will use the information already obtained to propose\n",
    "the set of hyper parameters that it considers that have the highest probability\n",
    "to obtain the best results.\n",
    "\n",
    "## Usage example \n",
    "\n",
    "In this example we will tune the\n",
    "[RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) against the [Boston dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html), creating a `Tunable` object with two of its\n",
    "hyperparameters and we will create a `Tuner` that will propose new\n",
    "set of hyperparameters in order to improve the score.\n",
    "\n",
    "First we will import `Tunable`, `GPTuner` and `IntHyperParam` that we\n",
    "will use to create our `tuner` that will improve our estiamtor's score. Then we will instantiate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.tuning import Tunable\n",
    "from btb.tuning.tuners import GPTuner\n",
    "from btb.tuning.hyperparams import IntHyperParam\n",
    "\n",
    "hyperparams = {\n",
    "    'n_estimators': IntHyperParam(min=10, max=500),\n",
    "    'max_depth': IntHyperParam(min=10, max=500),\n",
    "}\n",
    "\n",
    "tunable = Tunable(hyperparams)\n",
    "tuner = GPTuner(tunable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will import our dataset and our estimator.\n",
    "Then we will load and split our dataset in to train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "dataset = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     dataset.data, dataset.target, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the following three steps in a loop.\n",
    "\n",
    "1. Let the Tuner propose a new set of parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 83, 'max_depth': 393}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = tuner.propose()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit and score a new model using these parameters:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8218116410433008"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pass the used parameters and the score obtained back to the tuner:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.record(parameters, score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each iteration, the ``Tuner`` will use the information about the previous tests\n",
    "to evaluate and propose the set of parameter values that have the highest probability\n",
    "of obtaining the highest score.\n",
    "\n",
    "Below we present the loop that would store the best score obtained for 100 tuning iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for i in range(100):\n",
    "    parameters = tuner.propose()\n",
    "    model = RandomForestRegressor(**parameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameters = parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our loop finishes with the tuning, we can now print the `best_score` found for 100 iterations\n",
    "and also the `best_parameters` that obtained that score in order to reproduce it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8445775832444316"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 24, 'max_depth': 406}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
