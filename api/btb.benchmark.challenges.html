

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>btb.benchmark.challenges package &mdash; BTB 0.3.2.dev0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/dai-logo-white.ico"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="btb.benchmark.challenges.bohachevsky module" href="btb.benchmark.challenges.bohachevsky.html" />
    <link rel="prev" title="btb.benchmark package" href="btb.benchmark.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> BTB
          

          
            
            <img src="../_static/dai-logo-white-200.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../readme.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readme.html#install">Install</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../readme.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../readme.html#install-using-pip">Install using Pip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../readme.html#install-from-source">Install from Source</a></li>
<li class="toctree-l2"><a class="reference internal" href="../readme.html#install-for-development">Install for Development</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../readme.html#quickstart">Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../readme.html#tuners">Tuners</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../readme.html#selectors">Selectors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../readme.html#what-s-next">Whatâ€™s next?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../readme.html#citing-btb">Citing BTB</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Resources</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="btb.html">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="btb.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="btb.benchmark.html">btb.benchmark package</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="btb.benchmark.html#subpackages">Subpackages</a></li>
<li class="toctree-l4"><a class="reference internal" href="btb.benchmark.html#module-btb.benchmark">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="btb.selection.html">btb.selection package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="btb.selection.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="btb.selection.html#module-btb.selection">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="btb.tuning.html">btb.tuning package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="btb.tuning.html#subpackages">Subpackages</a></li>
<li class="toctree-l4"><a class="reference internal" href="btb.tuning.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="btb.tuning.html#module-btb.tuning">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="btb.html#module-btb">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#types-of-contributions">Types of Contributions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#report-bugs">Report Bugs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#fix-bugs">Fix Bugs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#implement-features">Implement Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#write-documentation">Write Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#submit-feedback">Submit Feedback</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#get-started">Get Started!</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#pull-request-guidelines">Pull Request Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#unit-testing-guidelines">Unit Testing Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#tips">Tips</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#release-workflow">Release Workflow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#release-candidates">Release Candidates</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../history.html">History</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../history.html#id1">0.3.1 - 2019-11-25</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#new-features">New Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../history.html#resolved-issues">Resolved Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#id2">0.3.0 - 2019-11-11</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#new-project-structure">New project structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../history.html#new-api">New API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id3">New Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id4">Resolved Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#id5">0.2.5</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#bug-fixes">Bug Fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#id6">0.2.4</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#internal-improvements">Internal Improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id7">Bug fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#id8">0.2.3</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id9">Bug Fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#id10">0.2.2</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id11">Internal Improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id12">Bug Fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#id13">0.2.1</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id14">Bug fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#id15">0.2.0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id16">New Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id17">Internal Improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id18">Bug Fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#id19">0.1.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#id20">0.1.1</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">BTB</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="btb.html">btb package</a> &raquo;</li>
        
          <li><a href="btb.benchmark.html">btb.benchmark package</a> &raquo;</li>
        
      <li>btb.benchmark.challenges package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/HDI-Project/BTB/blob/master/docs/api/btb.benchmark.challenges.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="btb-benchmark-challenges-package">
<h1>btb.benchmark.challenges package<a class="headerlink" href="#btb-benchmark-challenges-package" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">Â¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="btb.benchmark.challenges.bohachevsky.html">btb.benchmark.challenges.bohachevsky module</a></li>
<li class="toctree-l1"><a class="reference internal" href="btb.benchmark.challenges.branin.html">btb.benchmark.challenges.branin module</a></li>
<li class="toctree-l1"><a class="reference internal" href="btb.benchmark.challenges.census.html">btb.benchmark.challenges.census module</a></li>
<li class="toctree-l1"><a class="reference internal" href="btb.benchmark.challenges.challenge.html">btb.benchmark.challenges.challenge module</a></li>
<li class="toctree-l1"><a class="reference internal" href="btb.benchmark.challenges.rosenbrock.html">btb.benchmark.challenges.rosenbrock module</a></li>
</ul>
</div>
</div>
<div class="section" id="module-btb.benchmark.challenges">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-btb.benchmark.challenges" title="Permalink to this headline">Â¶</a></h2>
<p>Top level where all the challenges are imported.</p>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#btb.benchmark.challenges.Bohachevsky" title="btb.benchmark.challenges.Bohachevsky"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Bohachevsky</span></code></a>([min_x,Â max_x,Â min_y,Â max_y])</p></td>
<td><p>Bohachevsky challenge.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#btb.benchmark.challenges.Branin" title="btb.benchmark.challenges.Branin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Branin</span></code></a>([a,Â b,Â c,Â r,Â s,Â t,Â min_x,Â max_x,Â â€¦])</p></td>
<td><p>Branin challenge.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF" title="btb.benchmark.challenges.CensusRF"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CensusRF</span></code></a>([model,Â dataset,Â target_column,Â â€¦])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#btb.benchmark.challenges.Rosenbrock" title="btb.benchmark.challenges.Rosenbrock"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Rosenbrock</span></code></a>([a,Â b,Â min_x,Â max_x,Â min_y,Â max_y])</p></td>
<td><p>Rosenbrock Challenge.</p></td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="btb.benchmark.challenges.Bohachevsky">
<em class="property">class </em><code class="sig-prename descclassname">btb.benchmark.challenges.</code><code class="sig-name descname">Bohachevsky</code><span class="sig-paren">(</span><em class="sig-param">min_x=-100</em>, <em class="sig-param">max_x=100</em>, <em class="sig-param">min_y=-100</em>, <em class="sig-param">max_y=100</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/btb/benchmark/challenges/bohachevsky.html#Bohachevsky"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#btb.benchmark.challenges.Bohachevsky" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="btb.benchmark.challenges.challenge.html#btb.benchmark.challenges.challenge.Challenge" title="btb.benchmark.challenges.challenge.Challenge"><code class="xref py py-class docutils literal notranslate"><span class="pre">btb.benchmark.challenges.challenge.Challenge</span></code></a></p>
<p>Bohachevsky challenge.</p>
<p>The Bohachevsky functions are bowl shape functions. This function is usually evaluated on the
input domain <span class="math notranslate nohighlight">\(x \epsilon [-100, 100], y \epsilon [-100, 100]\)</span>.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p><a class="reference external" href="https://www.sfu.ca/~ssurjano/boha.html">https://www.sfu.ca/~ssurjano/boha.html</a></p>
</dd>
<dt>The function is defined by:</dt><dd><p><span class="math notranslate nohighlight">\(f(x, y) = x^2 + 2y^2 -0.3cos(3\pi x)-0.4cos(4\pi y)+0.7\)</span></p>
</dd>
<dt>It has one local minimum at:</dt><dd><p><span class="math notranslate nohighlight">\((x, y) = (0, 0)\)</span> where <span class="math notranslate nohighlight">\(f(x, y) = 0\)</span>.</p>
</dd>
</dl>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#btb.benchmark.challenges.Bohachevsky.evaluate" title="btb.benchmark.challenges.Bohachevsky.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(x,Â y)</p></td>
<td><p>Perform evaluation for the given <code class="docutils literal notranslate"><span class="pre">arguments</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#btb.benchmark.challenges.Bohachevsky.get_tunable_hyperparameters" title="btb.benchmark.challenges.Bohachevsky.get_tunable_hyperparameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_tunable_hyperparameters</span></code></a>()</p></td>
<td><p>Return a dictionary with hyperparameters to be tuned.</p></td>
</tr>
</tbody>
</table>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>min_x</strong> (<em>int</em>) â€“ Minimum number that the hyperparameter can propouse for <code class="docutils literal notranslate"><span class="pre">x</span></code>. Defaults to -100.</p></li>
<li><p><strong>max_x</strong> (<em>int</em>) â€“ Maximum number that the hyperparameter can propouse for <code class="docutils literal notranslate"><span class="pre">x</span></code>. Defaults to 100.</p></li>
<li><p><strong>min_y</strong> (<em>int</em>) â€“ Minimum number that the hyperparameter can propouse for <code class="docutils literal notranslate"><span class="pre">y</span></code>. Defaults to -100.</p></li>
<li><p><strong>max_y</strong> (<em>int</em>) â€“ Maximum number that the hyperparameter can propouse for <code class="docutils literal notranslate"><span class="pre">y</span></code>. Defaults to 100.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="btb.benchmark.challenges.Bohachevsky.evaluate">
<code class="sig-name descname">evaluate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/btb/benchmark/challenges/bohachevsky.html#Bohachevsky.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#btb.benchmark.challenges.Bohachevsky.evaluate" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Perform evaluation for the given <code class="docutils literal notranslate"><span class="pre">arguments</span></code>.</p>
<p>This method will score a result with a given configuration, then return the score obtained
for those <code class="docutils literal notranslate"><span class="pre">arguments</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="btb.benchmark.challenges.Bohachevsky.get_tunable_hyperparameters">
<code class="sig-name descname">get_tunable_hyperparameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/btb/benchmark/challenges/bohachevsky.html#Bohachevsky.get_tunable_hyperparameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#btb.benchmark.challenges.Bohachevsky.get_tunable_hyperparameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a dictionary with hyperparameters to be tuned.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="btb.benchmark.challenges.Branin">
<em class="property">class </em><code class="sig-prename descclassname">btb.benchmark.challenges.</code><code class="sig-name descname">Branin</code><span class="sig-paren">(</span><em class="sig-param">a=1</em>, <em class="sig-param">b=0.12918450914398066</em>, <em class="sig-param">c=1.5915494309189535</em>, <em class="sig-param">r=6</em>, <em class="sig-param">s=10</em>, <em class="sig-param">t=0.039788735772973836</em>, <em class="sig-param">min_x=-5.0</em>, <em class="sig-param">max_x=10.0</em>, <em class="sig-param">min_y=0.0</em>, <em class="sig-param">max_y=15.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/btb/benchmark/challenges/branin.html#Branin"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#btb.benchmark.challenges.Branin" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="btb.benchmark.challenges.challenge.html#btb.benchmark.challenges.challenge.Challenge" title="btb.benchmark.challenges.challenge.Challenge"><code class="xref py py-class docutils literal notranslate"><span class="pre">btb.benchmark.challenges.challenge.Challenge</span></code></a></p>
<p>Branin challenge.</p>
<p>The Branin, or Branin-Hoo, function is commonly used as a test function for metamodeling
in computer experiments, especially in the context of optimization. This function takes as
input <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> and has six constants that are named as <code class="docutils literal notranslate"><span class="pre">a,</span> <span class="pre">b,</span> <span class="pre">c,</span> <span class="pre">r,</span> <span class="pre">s,</span> <span class="pre">t</span></code>.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p><a class="reference external" href="https://uqworld.org/t/branin-function/53https://uqworld.org/t/branin-function/53">https://uqworld.org/t/branin-function/53https://uqworld.org/t/branin-function/53</a></p>
</dd>
<dt>The function is defined by:</dt><dd><p><span class="math notranslate nohighlight">\(f(x, y)=\left(y-\frac{5.1 x^2_1}{4 \pi^2}+\frac{5 x}{\pi}-6\right)^2+10\left(1-
\frac{1}{8 \pi}\right) \cos(x)+10\)</span></p>
</dd>
<dt>It has a global minimum, with the default <cite>a, b, c, r, s, t</cite> at the following three points:</dt><dd><p><span class="math notranslate nohighlight">\(f(x, y) = 0.397887\)</span> at <span class="math notranslate nohighlight">\(x, y = (-\pi, 12.275), (\pi, 2.275)\)</span> and
<span class="math notranslate nohighlight">\((9.42478, 2.475)\)</span></p>
</dd>
</dl>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#btb.benchmark.challenges.Branin.evaluate" title="btb.benchmark.challenges.Branin.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(x,Â y)</p></td>
<td><p>Perform evaluation for the given <code class="docutils literal notranslate"><span class="pre">arguments</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#btb.benchmark.challenges.Branin.get_tunable_hyperparameters" title="btb.benchmark.challenges.Branin.get_tunable_hyperparameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_tunable_hyperparameters</span></code></a>()</p></td>
<td><p>Return a dictionary with hyperparameters to be tuned.</p></td>
</tr>
</tbody>
</table>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>int</em>) â€“ Constant value for <code class="docutils literal notranslate"><span class="pre">a</span></code>. Defaults to 1.</p></li>
<li><p><strong>b</strong> (<em>float</em><em> or </em><em>int</em>) â€“ Constant value for <code class="docutils literal notranslate"><span class="pre">b</span></code>. Defaults to <span class="math notranslate nohighlight">\(5.1 / (4*\pi^2)\)</span>.</p></li>
<li><p><strong>c</strong> (<em>float</em><em> or </em><em>int</em>) â€“ Constant value for <code class="docutils literal notranslate"><span class="pre">c</span></code>. Defaults to <span class="math notranslate nohighlight">\(5 / \pi\)</span>.</p></li>
<li><p><strong>r</strong> (<em>int</em>) â€“ Constant value for <code class="docutils literal notranslate"><span class="pre">r</span></code>. Defaults to 6</p></li>
<li><p><strong>s</strong> (<em>int</em>) â€“ Constant value for <code class="docutils literal notranslate"><span class="pre">s</span></code>. Defaults to 10</p></li>
<li><p><strong>t</strong> (<em>float</em><em> or </em><em>int</em>) â€“ Constant value for <code class="docutils literal notranslate"><span class="pre">t</span></code>. Defaults to <span class="math notranslate nohighlight">\(1 / 8*\pi\)</span>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="btb.benchmark.challenges.Branin.evaluate">
<code class="sig-name descname">evaluate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/btb/benchmark/challenges/branin.html#Branin.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#btb.benchmark.challenges.Branin.evaluate" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Perform evaluation for the given <code class="docutils literal notranslate"><span class="pre">arguments</span></code>.</p>
<p>This method will score a result with a given configuration, then return the score obtained
for those <code class="docutils literal notranslate"><span class="pre">arguments</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="btb.benchmark.challenges.Branin.get_tunable_hyperparameters">
<code class="sig-name descname">get_tunable_hyperparameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/btb/benchmark/challenges/branin.html#Branin.get_tunable_hyperparameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#btb.benchmark.challenges.Branin.get_tunable_hyperparameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a dictionary with hyperparameters to be tuned.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="btb.benchmark.challenges.CensusRF">
<em class="property">class </em><code class="sig-prename descclassname">btb.benchmark.challenges.</code><code class="sig-name descname">CensusRF</code><span class="sig-paren">(</span><em class="sig-param">model=None</em>, <em class="sig-param">dataset=None</em>, <em class="sig-param">target_column=None</em>, <em class="sig-param">encode=False</em>, <em class="sig-param">tunable_hyperparameters=None</em>, <em class="sig-param">metric=None</em>, <em class="sig-param">model_defaults=None</em>, <em class="sig-param">make_binary=None</em>, <em class="sig-param">stratified=True</em>, <em class="sig-param">cv_splits=5</em>, <em class="sig-param">cv_random_state=42</em>, <em class="sig-param">cv_shuffle=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/btb/benchmark/challenges/census.html#CensusRF"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#btb.benchmark.challenges.CensusRF" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="btb.benchmark.challenges.challenge.html#btb.benchmark.challenges.challenge.MLChallenge" title="btb.benchmark.challenges.challenge.MLChallenge"><code class="xref py py-class docutils literal notranslate"><span class="pre">btb.benchmark.challenges.challenge.MLChallenge</span></code></a></p>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF.DATASET" title="btb.benchmark.challenges.CensusRF.DATASET"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DATASET</span></code></a></p></td>
<td><p>str(object=â€™â€™) -&gt; str</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF.ENCODE" title="btb.benchmark.challenges.CensusRF.ENCODE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ENCODE</span></code></a></p></td>
<td><p>bool(x) -&gt; bool</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF.MAKE_BINARY" title="btb.benchmark.challenges.CensusRF.MAKE_BINARY"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MAKE_BINARY</span></code></a></p></td>
<td><p>bool(x) -&gt; bool</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF.MODEL_DEFAULTS" title="btb.benchmark.challenges.CensusRF.MODEL_DEFAULTS"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MODEL_DEFAULTS</span></code></a></p></td>
<td><p>dict() -&gt; new empty dictionary</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF.TARGET_COLUMN" title="btb.benchmark.challenges.CensusRF.TARGET_COLUMN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TARGET_COLUMN</span></code></a></p></td>
<td><p>str(object=â€™â€™) -&gt; str</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF.TUNABLE_HYPERPARAMETERS" title="btb.benchmark.challenges.CensusRF.TUNABLE_HYPERPARAMETERS"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TUNABLE_HYPERPARAMETERS</span></code></a></p></td>
<td><p>dict() -&gt; new empty dictionary</p></td>
</tr>
</tbody>
</table>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF.METRIC" title="btb.benchmark.challenges.CensusRF.METRIC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">METRIC</span></code></a>(y_pred[,Â labels,Â pos_label,Â average,Â â€¦])</p></td>
<td><p>Compute the F1 score, also known as balanced F-score or F-measure</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF.evaluate" title="btb.benchmark.challenges.CensusRF.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(**hyperparams)</p></td>
<td><p>Apply cross validation to hyperparameter combination.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF.get_tunable_hyperparameters" title="btb.benchmark.challenges.CensusRF.get_tunable_hyperparameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_tunable_hyperparameters</span></code></a>()</p></td>
<td><p>Return a dictionary with hyperparameters to be tuned.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF.load_data" title="btb.benchmark.challenges.CensusRF.load_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_data</span></code></a>()</p></td>
<td><p>Load <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> over which to perform fit and evaluate.</p></td>
</tr>
</tbody>
</table>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#btb.benchmark.challenges.CensusRF.MODEL" title="btb.benchmark.challenges.CensusRF.MODEL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MODEL</span></code></a></p></td>
<td><p>A random forest classifier.</p></td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="btb.benchmark.challenges.CensusRF.DATASET">
<code class="sig-name descname">DATASET</code><em class="property"> = 'census.csv'</em><a class="headerlink" href="#btb.benchmark.challenges.CensusRF.DATASET" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="btb.benchmark.challenges.CensusRF.ENCODE">
<code class="sig-name descname">ENCODE</code><em class="property"> = True</em><a class="headerlink" href="#btb.benchmark.challenges.CensusRF.ENCODE" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="btb.benchmark.challenges.CensusRF.MAKE_BINARY">
<code class="sig-name descname">MAKE_BINARY</code><em class="property"> = True</em><a class="headerlink" href="#btb.benchmark.challenges.CensusRF.MAKE_BINARY" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="btb.benchmark.challenges.CensusRF.METRIC">
<code class="sig-name descname">METRIC</code><span class="sig-paren">(</span><em class="sig-param">y_pred</em>, <em class="sig-param">labels=None</em>, <em class="sig-param">pos_label=1</em>, <em class="sig-param">average='binary'</em>, <em class="sig-param">sample_weight=None</em><span class="sig-paren">)</span><a class="headerlink" href="#btb.benchmark.challenges.CensusRF.METRIC" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Compute the F1 score, also known as balanced F-score or F-measure</p>
<p>The F1 score can be interpreted as a weighted average of the precision and
recall, where an F1 score reaches its best value at 1 and worst score at 0.
The relative contribution of precision and recall to the F1 score are
equal. The formula for the F1 score is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">F1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>
</div>
<p>In the multi-class and multi-label case, this is the average of
the F1 score of each class with weighting depending on the <code class="docutils literal notranslate"><span class="pre">average</span></code>
parameter.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<em>1d array-like</em><em>, or </em><em>label indicator array / sparse matrix</em>) â€“ Ground truth (correct) target values.</p></li>
<li><p><strong>y_pred</strong> (<em>1d array-like</em><em>, or </em><em>label indicator array / sparse matrix</em>) â€“ Estimated targets as returned by a classifier.</p></li>
<li><p><strong>labels</strong> (<em>list</em><em>, </em><em>optional</em>) â€“ <p>The set of labels to include when <code class="docutils literal notranslate"><span class="pre">average</span> <span class="pre">!=</span> <span class="pre">'binary'</span></code>, and their
order if <code class="docutils literal notranslate"><span class="pre">average</span> <span class="pre">is</span> <span class="pre">None</span></code>. Labels present in the data can be
excluded, for example to calculate a multiclass average ignoring a
majority negative class, while labels not present in the data will
result in 0 components in a macro average. For multilabel targets,
labels are column indices. By default, all labels in <code class="docutils literal notranslate"><span class="pre">y_true</span></code> and
<code class="docutils literal notranslate"><span class="pre">y_pred</span></code> are used in sorted order.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.17: </span>parameter <em>labels</em> improved for multiclass problem.</p>
</div>
</p></li>
<li><p><strong>pos_label</strong> (<em>str</em><em> or </em><em>int</em><em>, </em><em>1 by default</em>) â€“ The class to report if <code class="docutils literal notranslate"><span class="pre">average='binary'</span></code> and the data is binary.
If the data are multiclass or multilabel, this will be ignored;
setting <code class="docutils literal notranslate"><span class="pre">labels=[pos_label]</span></code> and <code class="docutils literal notranslate"><span class="pre">average</span> <span class="pre">!=</span> <span class="pre">'binary'</span></code> will report
scores for that label only.</p></li>
<li><p><strong>average</strong> (<em>string</em><em>, </em><em>[</em><em>None</em><em>, </em><em>'binary'</em><em> (</em><em>default</em><em>)</em><em>, </em><em>'micro'</em><em>, </em><em>'macro'</em><em>, </em><em>'samples'</em><em>,                        </em><em>'weighted'</em><em>]</em>) â€“ <p>This parameter is required for multiclass/multilabel targets.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned. Otherwise, this
determines the type of averaging performed on the data:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">'binary'</span></code>:</dt><dd><p>Only report results for the class specified by <code class="docutils literal notranslate"><span class="pre">pos_label</span></code>.
This is applicable only if targets (<code class="docutils literal notranslate"><span class="pre">y_{true,pred}</span></code>) are binary.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'micro'</span></code>:</dt><dd><p>Calculate metrics globally by counting the total true positives,
false negatives and false positives.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'macro'</span></code>:</dt><dd><p>Calculate metrics for each label, and find their unweighted
mean.  This does not take label imbalance into account.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'weighted'</span></code>:</dt><dd><p>Calculate metrics for each label, and find their average weighted
by support (the number of true instances for each label). This
alters â€˜macroâ€™ to account for label imbalance; it can result in an
F-score that is not between precision and recall.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'samples'</span></code>:</dt><dd><p>Calculate metrics for each instance, and find their average (only
meaningful for multilabel classification where this differs from
<code class="xref py py-func docutils literal notranslate"><span class="pre">accuracy_score()</span></code>).</p>
</dd>
</dl>
</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>]</em><em>, </em><em>optional</em>) â€“ Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>f1_score</strong> â€“ F1 score of the positive class in binary classification or weighted
average of the F1 scores of each class for the multiclass task.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float or array of float, shape = [n_unique_labels]</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fbeta_score()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">precision_recall_fscore_support()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">jaccard_score()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">multilabel_confusion_matrix()</span></code></p>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id1"><span class="brackets">1</span></dt>
<dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/F1_score">Wikipedia entry for the F1-score</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>  
<span class="go">0.26...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>  
<span class="go">0.33...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>  
<span class="go">0.26...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([0.8, 0. , 0. ])</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>When <code class="docutils literal notranslate"><span class="pre">true</span> <span class="pre">positive</span> <span class="pre">+</span> <span class="pre">false</span> <span class="pre">positive</span> <span class="pre">==</span> <span class="pre">0</span></code> or
<code class="docutils literal notranslate"><span class="pre">true</span> <span class="pre">positive</span> <span class="pre">+</span> <span class="pre">false</span> <span class="pre">negative</span> <span class="pre">==</span> <span class="pre">0</span></code>, f-score returns 0 and raises
<code class="docutils literal notranslate"><span class="pre">UndefinedMetricWarning</span></code>.</p>
</dd></dl>

<dl class="attribute">
<dt id="btb.benchmark.challenges.CensusRF.MODEL">
<code class="sig-name descname">MODEL</code><a class="headerlink" href="#btb.benchmark.challenges.CensusRF.MODEL" title="Permalink to this definition">Â¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.ensemble.forest.RandomForestClassifier</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="btb.benchmark.challenges.CensusRF.MODEL_DEFAULTS">
<code class="sig-name descname">MODEL_DEFAULTS</code><em class="property"> = {'random_state': 0}</em><a class="headerlink" href="#btb.benchmark.challenges.CensusRF.MODEL_DEFAULTS" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="btb.benchmark.challenges.CensusRF.TARGET_COLUMN">
<code class="sig-name descname">TARGET_COLUMN</code><em class="property"> = 'income'</em><a class="headerlink" href="#btb.benchmark.challenges.CensusRF.TARGET_COLUMN" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="btb.benchmark.challenges.CensusRF.TUNABLE_HYPERPARAMETERS">
<code class="sig-name descname">TUNABLE_HYPERPARAMETERS</code><em class="property"> = {'criterion': {'default': 'gini', 'type': 'str', 'values': ['entropy', 'gini']}, 'max_features': {'default': None, 'type': 'str', 'values': [None, 'auto', 'log2', 'sqrt']}, 'min_impurity_decrease': {'default': 0.0, 'range': [0.0, 1000.0], 'type': 'float'}, 'min_samples_leaf': {'default': 1, 'range': [1, 100], 'type': 'int'}, 'min_samples_split': {'default': 2, 'range': [2, 100], 'type': 'int'}, 'min_weight_fraction_leaf': {'default': 0.0, 'range': [0.0, 0.5], 'type': 'float'}, 'n_estimators': {'default': 10, 'range': [1, 500], 'type': 'int'}}</em><a class="headerlink" href="#btb.benchmark.challenges.CensusRF.TUNABLE_HYPERPARAMETERS" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="btb.benchmark.challenges.CensusRF.evaluate">
<code class="sig-name descname">evaluate</code><span class="sig-paren">(</span><em class="sig-param">**hyperparams</em><span class="sig-paren">)</span><a class="headerlink" href="#btb.benchmark.challenges.CensusRF.evaluate" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Apply cross validation to hyperparameter combination.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hyperparams</strong> (<em>dict</em>) â€“ A combination of <code class="docutils literal notranslate"><span class="pre">self.tunable_hyperparams</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns the <code class="docutils literal notranslate"><span class="pre">mean</span></code> cross validated score.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>score (float)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="btb.benchmark.challenges.CensusRF.get_tunable_hyperparameters">
<code class="sig-name descname">get_tunable_hyperparameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#btb.benchmark.challenges.CensusRF.get_tunable_hyperparameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a dictionary with hyperparameters to be tuned.</p>
</dd></dl>

<dl class="method">
<dt id="btb.benchmark.challenges.CensusRF.load_data">
<code class="sig-name descname">load_data</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#btb.benchmark.challenges.CensusRF.load_data" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> over which to perform fit and evaluate.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="btb.benchmark.challenges.Rosenbrock">
<em class="property">class </em><code class="sig-prename descclassname">btb.benchmark.challenges.</code><code class="sig-name descname">Rosenbrock</code><span class="sig-paren">(</span><em class="sig-param">a=1</em>, <em class="sig-param">b=100</em>, <em class="sig-param">min_x=-50</em>, <em class="sig-param">max_x=50</em>, <em class="sig-param">min_y=-50</em>, <em class="sig-param">max_y=50</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/btb/benchmark/challenges/rosenbrock.html#Rosenbrock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#btb.benchmark.challenges.Rosenbrock" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="btb.benchmark.challenges.challenge.html#btb.benchmark.challenges.challenge.Challenge" title="btb.benchmark.challenges.challenge.Challenge"><code class="xref py py-class docutils literal notranslate"><span class="pre">btb.benchmark.challenges.challenge.Challenge</span></code></a></p>
<p>Rosenbrock Challenge.</p>
<p>This challenge represents the Rosenbrock function, this is a non-convex function, introduced by
Howard H. Rosenbrock in 1960, which is used as a performance test problem for optimization
algorithms.[1] It is also known as Rosenbrockâ€™s valley or Rosenbrockâ€™s banana function.</p>
<p>The global minimum is inside a long, narrow, parabolic shaped flat valley. To find the valley
is trivial. To converge to the global minimum, however, is difficult.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Rosenbrock_function">https://en.wikipedia.org/wiki/Rosenbrock_function</a></p>
</dd>
<dt>The function is defined by:</dt><dd><p><span class="math notranslate nohighlight">\(f(x, y) = (a - x)^2 + b(y - x ^2)^2\)</span></p>
</dd>
<dt>It has a global minimum at:</dt><dd><p><span class="math notranslate nohighlight">\((x, y) = (a, a^2)\)</span> where <cite>f(x, y) = 0</cite>. Usually these parameters are set such that
<span class="math notranslate nohighlight">\(a = 1\)</span> and <span class="math notranslate nohighlight">\(b = 100\)</span>. Only in the trivial case where <span class="math notranslate nohighlight">\(a = 0\)</span> is the
function symmetric and the minimum at the origin.</p>
</dd>
</dl>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#btb.benchmark.challenges.Rosenbrock.evaluate" title="btb.benchmark.challenges.Rosenbrock.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(x,Â y)</p></td>
<td><p>Perform evaluation for the given <code class="docutils literal notranslate"><span class="pre">arguments</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#btb.benchmark.challenges.Rosenbrock.get_tunable_hyperparameters" title="btb.benchmark.challenges.Rosenbrock.get_tunable_hyperparameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_tunable_hyperparameters</span></code></a>()</p></td>
<td><p>Return a dictionary with hyperparameters to be tuned.</p></td>
</tr>
</tbody>
</table>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>int</em>) â€“ Number that <code class="docutils literal notranslate"><span class="pre">a</span></code> will take in the function. Defaults to 1.</p></li>
<li><p><strong>b</strong> (<em>int</em>) â€“ Number that <code class="docutils literal notranslate"><span class="pre">b</span></code> will take in the function. Defaults to 100.</p></li>
<li><p><strong>min_x</strong> (<em>int</em>) â€“ Minimum number that the hyperparameter can propouse for <code class="docutils literal notranslate"><span class="pre">x</span></code>. Defaults to -50.</p></li>
<li><p><strong>max_x</strong> (<em>int</em>) â€“ Maximum number that the hyperparameter can propouse for <code class="docutils literal notranslate"><span class="pre">x</span></code>. Defaults to 50.</p></li>
<li><p><strong>min_y</strong> (<em>int</em>) â€“ Minimum number that the hyperparameter can propouse for <code class="docutils literal notranslate"><span class="pre">y</span></code>. Defaults to -50.</p></li>
<li><p><strong>max_y</strong> (<em>int</em>) â€“ Maximum number that the hyperparameter can propouse for <code class="docutils literal notranslate"><span class="pre">y</span></code>. Defaults to 50.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="btb.benchmark.challenges.Rosenbrock.evaluate">
<code class="sig-name descname">evaluate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/btb/benchmark/challenges/rosenbrock.html#Rosenbrock.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#btb.benchmark.challenges.Rosenbrock.evaluate" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Perform evaluation for the given <code class="docutils literal notranslate"><span class="pre">arguments</span></code>.</p>
<p>This method will score a result with a given configuration, then return the score obtained
for those <code class="docutils literal notranslate"><span class="pre">arguments</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="btb.benchmark.challenges.Rosenbrock.get_tunable_hyperparameters">
<code class="sig-name descname">get_tunable_hyperparameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/btb/benchmark/challenges/rosenbrock.html#Rosenbrock.get_tunable_hyperparameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#btb.benchmark.challenges.Rosenbrock.get_tunable_hyperparameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a dictionary with hyperparameters to be tuned.</p>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="btb.benchmark.challenges.bohachevsky.html" class="btn btn-neutral float-right" title="btb.benchmark.challenges.bohachevsky module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="btb.benchmark.html" class="btn btn-neutral float-left" title="btb.benchmark package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, MIT Data To AI Lab

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>